{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In colab run this cell first to setup the file structure!\n",
    "%cd /content\n",
    "!rm -rf MOL518-Intro-to-Data-Analysis\n",
    "\n",
    "!git clone https://github.com/shaevitz/MOL518-Intro-to-Data-Analysis.git\n",
    "%cd MOL518-Intro-to-Data-Analysis/Lecture_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf2bdd",
   "metadata": {},
   "source": [
    "# Lecture 5: Working with files and folders\n",
    "\n",
    "In scientific computing, you will often need to work with many files organized into folders (also called directories). If you have experience using the command line (Terminal on Mac or Command Prompt/PowerShell on Windows), this will feel familiar. If you have only ever navigated files by clicking through Finder (Mac) or File Explorer (Windows), this programmatic approach may feel new, but it is a powerful skill that will save you time when processing large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11465957",
   "metadata": {},
   "source": [
    "The goals of this lecture are to:\n",
    "\n",
    "- Learn about the working directory\n",
    "- Build paths using `pathlib.Path`\n",
    "- List the contents of a folder from inside Python\n",
    "- Find groups of files using patterns\n",
    "- Loop over many files and compute summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11094b9b",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We will need to import two new packages\n",
    "\n",
    "- `pathlib.Path` for working with file paths\n",
    "- `csv` module for writing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09565f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393a03e",
   "metadata": {},
   "source": [
    "## Navigating the file system\n",
    "\n",
    "### Files and folders\n",
    "- A **folder** (also called a directory) can contain files and other folders.\n",
    "- A **file** holds content, such as numbers in a CSV file, text in a document, or pixels in an image.\n",
    "\n",
    "### File extensions\n",
    "A file extension is the suffix after the last dot in a filename and is used to give you information about what is stored in the file.\n",
    "\n",
    "- `growth_curve.csv` has the extension `.csv`. A `Comma-Separated Values` file is a plain text file format for storing tabular data, where each row is a data record and columns are separated by commas (or other characters like tabs or semi-colons).\n",
    "- A `.jpg` file contains an image ...\n",
    "\n",
    "\n",
    "### Paths\n",
    "A **path** is a description of where a file or folder resides within the computer system.\n",
    "\n",
    "- A **relative path** is interpreted relative to your current working directory.\n",
    "  - Example: `data/raw/experiment.csv` (same on Mac and Windows when using Python's pathlib)\n",
    "  - Example: `../Lecture_4/data.csv` (go up one folder first)\n",
    "\n",
    "- An **absolute path** describes a location starting from the top of the file system.\n",
    "  - Mac example: `/Users/username/Documents/project/data.csv`\n",
    "  - Windows example: `C:\\Users\\username\\Documents\\project\\data.csv`\n",
    "\n",
    "> It is often useful to use relative paths because they work across different computers/systems as long as the project folder structure is consistent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283d814",
   "metadata": {},
   "source": [
    "## The working directory\n",
    "\n",
    "When Python opens a file using a relative path, what is it relative to? That reference point is called the **working directory**. You can think of it as the folder where Python is currently working.\n",
    "\n",
    "If the working directory is not what you expect, your code will fail to find files even if they exist. In Colab, the working directory can reset if you restart the runtime or open the notebook in a different way.\n",
    "\n",
    "> A good habit is to print the current working directory before you load data,  to make sure you are where you think you are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252982be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/jshaevitz/Library/CloudStorage/Dropbox/Documents/Teaching/MOL518_Programming/MOL518-Intro-to-Data-Analysis/Lecture_5')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current working directory as a Path object.\n",
    "Path.cwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165492b",
   "metadata": {},
   "source": [
    "If you ran the setup cell at the top of this notebook, your working directory should end with:\n",
    "\n",
    "`/content/MOL518-Intro-to-Data-Analysis/Lecture_5`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c2f8ec",
   "metadata": {},
   "source": [
    "## Listing the contents of a folder\n",
    "\n",
    "We can still explore the the contents of a folder from inside Python.\n",
    "\n",
    "`Path.iterdir()` lists the contents of a folder. It returns a sequence of **Path objects**. We will use the `list()` function to convert it to a list so we can print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc4c1a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/jshaevitz/Library/CloudStorage/Dropbox/Documents/Teaching/MOL518_Programming/MOL518-Intro-to-Data-Analysis/Lecture_5/.DS_Store'),\n",
       " PosixPath('/Users/jshaevitz/Library/CloudStorage/Dropbox/Documents/Teaching/MOL518_Programming/MOL518-Intro-to-Data-Analysis/Lecture_5/MOL518_Lecture5.ipynb'),\n",
       " PosixPath('/Users/jshaevitz/Library/CloudStorage/Dropbox/Documents/Teaching/MOL518_Programming/MOL518-Intro-to-Data-Analysis/Lecture_5/data')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the contents of the current working directory\n",
    "entries = list(Path.cwd().iterdir())\n",
    "entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c9833",
   "metadata": {},
   "source": [
    "You should see folders such as `data` in the list. The exact set depends on your repository layout.\n",
    "\n",
    "### Exercise 1\n",
    "Find the `data` folder in the printed list above. What other folders do you see at the top level of the repository?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee1209",
   "metadata": {},
   "source": [
    "## Building paths with `pathlib.Path`\n",
    "\n",
    "In earlier lectures you passed filenames to functions as strings. That works, but it becomes fragile when you start combining folders and filenames.\n",
    "\n",
    "`pathlib.Path` lets you build paths in a way that works across operating systems.\n",
    "\n",
    "A key feature is that you can join path pieces using `/`.\n",
    "\n",
    "For example, `Path(\"data\") / \"raw\"` means: a folder named `raw` inside a folder named `data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = Path(\"data\") / \"raw\"\n",
    "raw_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50200ee4",
   "metadata": {},
   "source": [
    "Before we do anything with a path, we should check whether it exists.\n",
    "\n",
    "- `.exists()` tells you whether something is there\n",
    "- `.is_dir()` tells you whether it is a folder\n",
    "- `.is_file()` tells you whether it is a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9471ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir.exists(), raw_dir.is_dir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f58e5b",
   "metadata": {},
   "source": [
    "If this prints `(False, False)`, then Python cannot find `data/raw` from your current working directory.\n",
    "\n",
    "In that case, stop and check:\n",
    "\n",
    "- Did you run the setup cell at the top of the notebook\n",
    "- Are you in the correct lecture folder\n",
    "- Does the repository contain the `data/raw` folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b1b9c",
   "metadata": {},
   "source": [
    "## The growth curve dataset layout\n",
    "\n",
    "For this lecture, the growth curves are organized like this:\n",
    "\n",
    "- `data/raw/DrugName/DrugName_rep1.csv`\n",
    "- `data/raw/DrugName/DrugName_rep2.csv`\n",
    "\n",
    "So the folder name tells you the drug condition, and each file inside is one replicate.\n",
    "\n",
    "Let us list the drug folders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_folders = sorted([p for p in raw_dir.iterdir() if p.is_dir()])\n",
    "\n",
    "# Print a clean list of folder names\n",
    "for p in drug_folders:\n",
    "    print(p.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c83cd",
   "metadata": {},
   "source": [
    "## Finding files with patterns using `glob`\n",
    "\n",
    "Often you want \"all CSV files in this folder\".\n",
    "\n",
    "`glob` finds paths that match a pattern.\n",
    "\n",
    "- `*.csv` means: any filename that ends in `.csv`\n",
    "\n",
    "This does not load the files. It only finds their paths.\n",
    "\n",
    "Let us choose one drug folder and see what is inside.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdb1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the first drug folder in the list\n",
    "example_drug_dir = drug_folders[0]\n",
    "example_drug_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_csv_files = sorted(list(example_drug_dir.glob(\"*.csv\")))\n",
    "\n",
    "print(\"Number of CSV files found:\", len(example_csv_files))\n",
    "for p in example_csv_files:\n",
    "    print(p.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cfb579",
   "metadata": {},
   "source": [
    "Printing the paths before loading anything is a safety habit.\n",
    "\n",
    "If you find zero files, you should fix the path or the pattern before proceeding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387b159",
   "metadata": {},
   "source": [
    "## Loading one growth curve file\n",
    "\n",
    "Each growth curve CSV contains two columns:\n",
    "\n",
    "- Time\n",
    "- Optical density (OD)\n",
    "\n",
    "The first row is a header, so we tell NumPy to skip it.\n",
    "\n",
    "In this lecture we will compute a few simple values that we can do with the tools you already know:\n",
    "\n",
    "- The replicate number (from the filename)\n",
    "- The total number of time points\n",
    "- The last OD value\n",
    "\n",
    "We will use the last OD values from both replicates to compute one number per drug: the average last OD across replicates.\n",
    "\n",
    "We will also compute the total elapsed time as a sanity check, but we will not put it into the per drug tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single replicate file\n",
    "path = example_csv_files[0]\n",
    "\n",
    "data = np.loadtxt(path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "time = data[:, 0]\n",
    "od = data[:, 1]\n",
    "\n",
    "print(\"File:\", path.name)\n",
    "print(\"Number of time points:\", len(time))\n",
    "print(\"First time:\", time[0])\n",
    "print(\"Last time:\", time[-1])\n",
    "print(\"Last OD:\", od[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f96842",
   "metadata": {},
   "source": [
    "## Extracting metadata from filenames\n",
    "\n",
    "In real workflows, important information often lives in folder names and filenames.\n",
    "\n",
    "Our files follow a simple naming pattern:\n",
    "\n",
    "`DrugName_rep1.csv`\n",
    "\n",
    "The part before `.csv` is called the **stem**.\n",
    "\n",
    "We can access pieces of a path like this:\n",
    "\n",
    "- `path.name` gives the full filename\n",
    "- `path.stem` gives the filename without the extension\n",
    "\n",
    "We will extract the replicate number from the stem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d40da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = path.stem\n",
    "stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to parse replicate numbers from stems like \"Ampicillin_rep2\"\n",
    "\n",
    "def replicate_number_from_stem(stem):\n",
    "    # We expect something like \"..._rep2\"\n",
    "    if \"_rep\" not in stem:\n",
    "        return None\n",
    "    rep_part = stem.split(\"_rep\")[-1]\n",
    "\n",
    "    # Convert to an integer if possible\n",
    "    try:\n",
    "        return int(rep_part)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "replicate_number_from_stem(stem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89308248",
   "metadata": {},
   "source": [
    "If the function returns `None`, that means the filename did not match the expected pattern.\n",
    "\n",
    "That is not a disaster. It is a signal that your assumptions about the dataset naming were wrong.\n",
    "\n",
    "In batch workflows, naming conventions matter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd915ffc",
   "metadata": {},
   "source": [
    "## A small per file summary function\n",
    "\n",
    "Batch processing becomes much easier if you can describe what you do to one file.\n",
    "\n",
    "We will write a function that takes a file path and returns a dictionary of results.\n",
    "\n",
    "This does not introduce new ideas. It just packages existing code so we can reuse it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_growth_curve(csv_path):\n",
    "    \"\"\"Load one growth curve CSV and return a summary dictionary.\"\"\"\n",
    "\n",
    "    data = np.loadtxt(csv_path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "    time = data[:, 0]\n",
    "    od = data[:, 1]\n",
    "\n",
    "    rep_num = replicate_number_from_stem(csv_path.stem)\n",
    "    last_od = od[-1]\n",
    "    n_time_points = len(time)\n",
    "    elapsed_time = time[-1] - time[0]\n",
    "\n",
    "    return {\n",
    "        \"replicate\": rep_num,\n",
    "        \"last_od\": last_od,\n",
    "        \"n_time_points\": n_time_points,\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"file\": csv_path.name,\n",
    "    }\n",
    "\n",
    "# Try it on one file\n",
    "summarize_growth_curve(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941cc7ec",
   "metadata": {},
   "source": [
    "## Batch processing all replicates for one drug\n",
    "\n",
    "Now we scale up from one file to many.\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Find all replicate CSV files for a drug folder\n",
    "2. Summarize each file\n",
    "3. Create a small table that has one row per replicate\n",
    "4. Compute the average last OD across replicates\n",
    "\n",
    "In the full batch processing section, we will save one replicate table per drug to disk.\n",
    "That table will include:\n",
    "\n",
    "- Replicate number\n",
    "- Total number of time points\n",
    "- Average last OD for that drug (the same number repeated for each replicate row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e434e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dir = example_drug_dir\n",
    "replicate_files = sorted(list(drug_dir.glob(\"*.csv\")))\n",
    "\n",
    "replicate_rows = []\n",
    "\n",
    "for csv_path in replicate_files:\n",
    "    row = summarize_growth_curve(csv_path)\n",
    "    replicate_rows.append(row)\n",
    "\n",
    "print(\"Drug:\", drug_dir.name)\n",
    "print(\"Number of replicate files:\", len(replicate_rows))\n",
    "\n",
    "# Print the table in a readable way\n",
    "for row in replicate_rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dfa9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average last OD across replicates\n",
    "last_ods = [row[\"last_od\"] for row in replicate_rows]\n",
    "\n",
    "avg_last_od = sum(last_ods) / len(last_ods)\n",
    "print(\"Average last OD for\", drug_dir.name, \":\", avg_last_od)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e109523",
   "metadata": {},
   "source": [
    "This average is a simple summary of growth under that drug condition.\n",
    "\n",
    "In later lectures you will learn more sophisticated summaries, but the workflow pattern will stay the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e195a",
   "metadata": {},
   "source": [
    "## Writing output tables to disk\n",
    "\n",
    "In a real workflow, you do not want results only printed to the screen.\n",
    "\n",
    "You want to save them so you can:\n",
    "\n",
    "- Load them later\n",
    "- Share them\n",
    "- Plot them\n",
    "\n",
    "We will save outputs in a separate folder.\n",
    "\n",
    "We will never overwrite the raw data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = Path(\"data\") / \"processed\"\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the per replicate table for this drug\n",
    "output_path = processed_dir / f\"{drug_dir.name}_replicate_table.csv\"\n",
    "\n",
    "fieldnames = [\"replicate\", \"last_od\", \"n_time_points\", \"elapsed_time\", \"file\"]\n",
    "\n",
    "with open(output_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(replicate_rows)\n",
    "\n",
    "print(\"Wrote:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ca7f2",
   "metadata": {},
   "source": [
    "## Full batch processing: all drugs\n",
    "\n",
    "Now we do the same procedure for every drug folder.\n",
    "\n",
    "For each drug we will:\n",
    "\n",
    "- Find the replicate files\n",
    "- Compute a small summary for each replicate\n",
    "- Compute the average last OD across the replicates\n",
    "- Save a table for that drug in `data/processed`\n",
    "\n",
    "Each per drug table will have one row per replicate with these columns:\n",
    "\n",
    "- `replicate`\n",
    "- `n_time_points`\n",
    "- `avg_last_od` (the average across replicates for that drug)\n",
    "\n",
    "We will also build an overall summary table that has one row per drug.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5600e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "\n",
    "drug_summary_rows = []\n",
    "failed_files = []\n",
    "\n",
    "for drug_dir in drug_folders:\n",
    "    replicate_files = sorted(list(drug_dir.glob(\"*.csv\")))\n",
    "\n",
    "    replicate_rows = []\n",
    "\n",
    "    for csv_path in replicate_files:\n",
    "        try:\n",
    "            row = summarize_growth_curve(csv_path)\n",
    "            replicate_rows.append(row)\n",
    "        except Exception as e:\n",
    "            failed_files.append({\"drug\": drug_dir.name, \"file\": csv_path.name, \"error\": str(e)})\n",
    "            if verbose:\n",
    "                print(\"Failed:\", drug_dir.name, csv_path.name)\n",
    "                print(\"Error:\", e)\n",
    "\n",
    "    if len(replicate_rows) == 0:\n",
    "        if verbose:\n",
    "            print(\"No replicate files found for\", drug_dir.name)\n",
    "        continue\n",
    "\n",
    "    # Compute average last OD across replicates for this drug\n",
    "    last_ods = [row[\"last_od\"] for row in replicate_rows]\n",
    "    avg_last_od = sum(last_ods) / len(last_ods)\n",
    "\n",
    "    # Build a per drug table where each row is one replicate.\n",
    "    # Each row includes the drug average, repeated, because it is a per drug value.\n",
    "    per_drug_table_rows = []\n",
    "    for row in replicate_rows:\n",
    "        per_drug_table_rows.append({\n",
    "            \"replicate\": row[\"replicate\"],\n",
    "            \"n_time_points\": row[\"n_time_points\"],\n",
    "            \"avg_last_od\": avg_last_od,\n",
    "        })\n",
    "\n",
    "    # Save the per drug replicate table\n",
    "    per_drug_output = processed_dir / f\"{drug_dir.name}_replicate_table.csv\"\n",
    "    fieldnames = [\"replicate\", \"n_time_points\", \"avg_last_od\"]\n",
    "\n",
    "    with open(per_drug_output, \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(per_drug_table_rows)\n",
    "\n",
    "    # Add one row to the overall drug summary table\n",
    "    drug_summary_rows.append({\n",
    "        \"drug\": drug_dir.name,\n",
    "        \"n_replicates\": len(replicate_rows),\n",
    "        \"avg_last_od\": avg_last_od,\n",
    "    })\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Processed\", drug_dir.name, \"with\", len(replicate_rows), \"replicates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the overall drug summary table\n",
    "summary_output = processed_dir / \"drug_summary_table.csv\"\n",
    "\n",
    "with open(summary_output, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"drug\", \"n_replicates\", \"avg_last_od\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(drug_summary_rows)\n",
    "\n",
    "print(\"Wrote:\", summary_output)\n",
    "print(\"Number of drugs summarized:\", len(drug_summary_rows))\n",
    "\n",
    "if len(failed_files) > 0:\n",
    "    print(\"\n",
    "Some files failed to process. Here are the failures:\")\n",
    "    for item in failed_files:\n",
    "        print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21caf70a",
   "metadata": {},
   "source": [
    "If you want to double check your results, open one of the saved CSV files in `data/processed`.\n",
    "\n",
    "The most important outcome of this lecture is not the specific numbers, but the workflow:\n",
    "\n",
    "- Find files\n",
    "- Loop\n",
    "- Summarize\n",
    "- Save outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d164dab",
   "metadata": {},
   "source": [
    "## Reporting failures\n",
    "\n",
    "In batch processing, one bad file should not crash everything.\n",
    "\n",
    "At the same time, you should never silently ignore failures.\n",
    "\n",
    "We kept a list of failed files, if any. Let us print it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(failed_files) == 0:\n",
    "    print(\"No failures detected.\")\n",
    "else:\n",
    "    print(\"Failures:\")\n",
    "    for item in failed_files:\n",
    "        print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d13692c",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 2\n",
    "Modify `summarize_growth_curve` so it also returns the first OD value.\n",
    "\n",
    "### Exercise 3\n",
    "For each drug, check whether the two replicates have the same number of time points. If not, print a warning.\n",
    "\n",
    "### Exercise 4\n",
    "Create a new summary table that includes the elapsed time for each drug. One simple choice is to average the elapsed times across replicates.\n",
    "\n",
    "Work slowly and use the habits from this lecture.\n",
    "\n",
    "- Print the paths you are using\n",
    "- Print the number of files found\n",
    "- Print a few intermediate results before writing files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa71bc",
   "metadata": {},
   "source": [
    "## Common failure modes\n",
    "\n",
    "- Forgetting that relative paths depend on the working directory\n",
    "- Typing folder names that do not match the actual names on disk\n",
    "- Using `glob` and not checking whether you found the files you expected\n",
    "- Confusing a `Path` object with the file contents\n",
    "- Writing outputs into the wrong folder and then not being able to find them\n",
    "\n",
    "If you get stuck, the most important debugging step is still the simplest.\n",
    "\n",
    "Print what you think you are using, then compare it to what is actually happening.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
