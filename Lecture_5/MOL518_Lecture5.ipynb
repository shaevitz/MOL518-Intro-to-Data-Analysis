{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In colab run this cell first to setup the file structure!\n",
    "%cd /content\n",
    "!rm -rf MOL518-Intro-to-Data-Analysis\n",
    "\n",
    "!git clone https://github.com/shaevitz/MOL518-Intro-to-Data-Analysis.git\n",
    "%cd MOL518-Intro-to-Data-Analysis/Lecture_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf2bdd",
   "metadata": {},
   "source": [
    "# Lecture 5: Working with files and folders\n",
    "\n",
    "In scientific computing, you will often need to work with many files organized into folders (also called directories). If you have experience using the command line (Terminal on Mac or Command Prompt/PowerShell on Windows), this will feel familiar. If you have only ever navigated files by clicking through Finder (Mac) or File Explorer (Windows), this programmatic approach may feel new, but it is a powerful skill that will save you time when processing large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11465957",
   "metadata": {},
   "source": [
    "The goals of this lecture are to:\n",
    "\n",
    "- Learn about the working directory\n",
    "- Build paths using `pathlib.Path`\n",
    "- List the contents of a folder from inside Python\n",
    "- Find groups of files using patterns\n",
    "- Loop over many files and compute summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11094b9b",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We will need to import two new packages\n",
    "\n",
    "- `pathlib.Path` for working with file paths\n",
    "- `csv` module for writing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09565f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393a03e",
   "metadata": {},
   "source": [
    "## Navigating the file system\n",
    "\n",
    "### Files and folders\n",
    "- A **folder** (also called a directory) can contain files and other folders.\n",
    "- A **file** holds content, such as numbers in a CSV file, text in a document, or pixels in an image.\n",
    "\n",
    "### File extensions\n",
    "A file extension is the suffix after the last dot in a filename and is used to give you information about what is stored in the file.\n",
    "\n",
    "- `growth_curve.csv` has the extension `.csv`. A `Comma-Separated Values` file is a plain text file format for storing tabular data, where each row is a data record and columns are separated by commas (or other characters like tabs or semi-colons).\n",
    "- A `.jpg` file contains an image ...\n",
    "\n",
    "\n",
    "### Paths\n",
    "A **path** is a description of where a file or folder resides within the computer system.\n",
    "\n",
    "- A **relative path** is interpreted relative to your current working directory.\n",
    "  - Example: `data/raw/experiment.csv` (same on Mac and Windows when using Python's pathlib)\n",
    "  - Example: `../Lecture_4/data.csv` (go up one folder first)\n",
    "\n",
    "- An **absolute path** describes a location starting from the top of the file system.\n",
    "  - Mac example: `/Users/username/Documents/project/data.csv`\n",
    "  - Windows example: `C:\\Users\\username\\Documents\\project\\data.csv`\n",
    "\n",
    "> It is often useful to use relative paths because they work across different computers/systems as long as the project folder structure is consistent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283d814",
   "metadata": {},
   "source": [
    "## The working directory\n",
    "\n",
    "When Python opens a file using a relative path, what is it relative to? That reference point is called the **working directory**. You can think of it as the folder where Python is currently working.\n",
    "\n",
    "If the working directory is not what you expect, your code will fail to find files even if they exist. In Colab, the working directory can reset if you restart the runtime or open the notebook in a different way.\n",
    "\n",
    "> A good habit is to print the current working directory before you load data,  to make sure you are where you think you are.\n",
    "\n",
    "`Path` is a class that represents file and folder paths. Classes are collections of related functionality bundled together. We've seen this before: in Lecture 2 we used `np.array()` to create NumPy arrays, and in Lecture 3 we used methods like `.plot()` on matplotlib objects.\n",
    "\n",
    "`Path.cwd()` is a function that belongs to the `Path` class that returns the current working directory as a Path object. The parentheses `()` mean we are *calling* the method to execute it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252982be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory as a Path object.\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165492b",
   "metadata": {},
   "source": [
    "If you ran the setup cell at the top of this notebook, your working directory should look like:\n",
    "\n",
    "`/content/MOL518-Intro-to-Data-Analysis/Lecture_5`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c2f8ec",
   "metadata": {},
   "source": [
    "## Listing the contents of a folder\n",
    "\n",
    "We can still explore the the contents of a folder from inside Python.\n",
    "\n",
    "The `Path.iterdir()` function lists the contents of a folder. It returns a sequence of **Path objects**. We will use the `list()` function to convert it to a list so we can print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the contents of the current working directory\n",
    "entries = list(Path.cwd().iterdir())\n",
    "entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee1209",
   "metadata": {},
   "source": [
    "## Building paths with `pathlib.Path`\n",
    "\n",
    "In earlier lectures we have written the filename directly into the code cells. That works, but it becomes tedious if you have many files and fragile when you start combining folders and filenames.\n",
    "\n",
    "`pathlib.Path` lets you build paths in a way that works across systems and operating systems.\n",
    "\n",
    "You can join path pieces using `/`. For example, `Path(\"data\") / \"ecoli_drug_curves\"` means: a folder named `ecoli_drug_curves` inside a folder named `data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"data\") / \"ecoli_drug_curves\"\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50200ee4",
   "metadata": {},
   "source": [
    "Before we do anything with a path, it's good to check whether it exists:\n",
    "\n",
    "- `.exists()` tells you whether something is there\n",
    "- `.is_dir()` tells you whether it is a folder\n",
    "- `.is_file()` tells you whether it is a file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9471ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir.exists(), data_dir.is_dir(), data_dir.is_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b1b9c",
   "metadata": {},
   "source": [
    "## Navigating a complex directory structure\n",
    "\n",
    "For this lecture, I have put the antibiotic growth curve replicates into folders based on the drug name via the following convention:\n",
    "\n",
    "- `data/ecoli_drug_curves/DrugName/DrugName_rep1.csv`\n",
    "- `data/ecoli_drug_curves/DrugName/DrugName_rep2.csv`\n",
    "\n",
    "We'll start by listing all the folders inside `data/` that represent the different drugs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_dir.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdb5dc7",
   "metadata": {},
   "source": [
    "Let's make a nicer list alphabetized by drug name. \n",
    "\n",
    "First, we will use a `for` loop to go through the contents of `data_dir` and keep only the items that are folders (not files). Then we will sort the list alphabetically.\n",
    "\n",
    "Note that the `.name` attribute of a Path object returns only the final component of the path, i.e. just the filename or the last folder name, without any of the parent directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build a list of only the folders (not files) in data_dir\n",
    "drug_folders_list = []\n",
    "for p in data_dir.iterdir():\n",
    "    if p.is_dir():\n",
    "        drug_folders_list.append(p) # appends the current folder to the list\n",
    "\n",
    "# Step 2: Sort them alphabetically by name\n",
    "drug_folders = sorted(drug_folders_list)\n",
    "\n",
    "# Step 3: Print a clean list of folder names\n",
    "print(\"Drug folders found:\")\n",
    "for p in drug_folders:\n",
    "    print(p.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c83cd",
   "metadata": {},
   "source": [
    "Above we used the `sorted` function which takes a list or sequence and returns a new list with the same items arranged in order (alphabetically for text, numerically for numbers). This makes the output easier to read.\n",
    "\n",
    "## Finding files with patterns using `glob`\n",
    "\n",
    "Sometimes you want to load all files of a particular type from a folder, like \"all CSV files in this directory\" or \"all PNG images from this experiment\".\n",
    "\n",
    "The `glob` method finds file paths that match a pattern using **wildcards**:\n",
    "\n",
    "- `*.csv` means: any filename that ends in `.csv`\n",
    "- `data_*.txt` means: any filename that starts with `data_` and ends in `.txt`\n",
    "- `*` by itself means: everything\n",
    "\n",
    "Wildcards are a quick way to describe groups of files without listing each one by hand. Note, the `glob` function only finds the paths; it does not load or open the files.\n",
    "\n",
    "Let's list all the CSV files inside one the first drug folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdb1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the first drug folder in the list\n",
    "example_drug_dir = drug_folders[0]\n",
    "example_drug_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a03f0",
   "metadata": {},
   "source": [
    "If we list all the files, we see there are some non-CSV files with other information in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(example_drug_dir.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48546380",
   "metadata": {},
   "source": [
    "We can use `*.csv` to find only the CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_csv_files = sorted(list(example_drug_dir.glob(\"*.csv\")))\n",
    "\n",
    "print(\"Number of CSV files found:\", len(example_csv_files))\n",
    "for p in example_csv_files:\n",
    "    print(p.name) # Note, here name prints the filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387b159",
   "metadata": {},
   "source": [
    "## Loading one growth curve file\n",
    "\n",
    "Each growth curve CSV contains two columns as before, Time and OD. The first row is a header, so we need to remember to tell NumPy to skip it.\n",
    "\n",
    "Here is example code that loads the first file in `example_drug_dir` and prints some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(example_csv_files[0], delimiter=\",\", skiprows=1)\n",
    "\n",
    "time = data[:, 0]\n",
    "od = data[:, 1]\n",
    "\n",
    "print(\"File:\", example_csv_files[0].name)\n",
    "print(\"Number of time points:\", len(time))\n",
    "print(\"First time:\", time[0])\n",
    "print(\"Last time:\", time[-1])\n",
    "print(\"First OD:\", od[0])\n",
    "print(\"Last OD:\", od[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f443f24",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write code to load both CSV files in `example_drug_dir` and calculate the average Last OD measurement. Use paths and a for loop over the files as we've been discussing for your code rather than hard coding the file names etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c161df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f96842",
   "metadata": {},
   "source": [
    "### Extracting metadata from filenames\n",
    "\n",
    "In real workflows, important information often lives in folder names and filenames.\n",
    "\n",
    "Our files follow a simple naming pattern:\n",
    "\n",
    "`DrugName_rep1.csv`\n",
    "\n",
    "The part before `.csv` is called the **stem**.\n",
    "\n",
    "We can access pieces of a path like this:\n",
    "\n",
    "- `path.name` gives the full filename\n",
    "- `path.stem` gives the filename without the extension\n",
    "\n",
    "Below we print the Path, name, and stem of `example_csv_files[0]`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_csv_files[0], example_csv_files[0].name, example_csv_files[0].stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941cc7ec",
   "metadata": {},
   "source": [
    "## Batch processing multiple files\n",
    "\n",
    "We will now use 'for' loops to systematically go through all the folders in the `ecoli_drug_curves` folder and compile a list calculate the number of replicates in each one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e434e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate_counts = []\n",
    "\n",
    "for i in range(len(drug_folders)):\n",
    "    # Find all CSV files in this drug folder\n",
    "    replicate_files = list(drug_folders[i].glob(\"*.csv\"))\n",
    "\n",
    "    # Store the count in a simple list\n",
    "    replicate_counts.append(len(replicate_files))\n",
    "\n",
    "print(\"Number of replicates by drug:\")\n",
    "for i in range(len(drug_folders)):\n",
    "    print(drug_folders[i].name + \": \" + str(replicate_counts[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e109523",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Write code to go through all the drug folders and plot the final OD measurement averaged over the two replicates and display a summary of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c259aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e195a",
   "metadata": {},
   "source": [
    "## Writing output tables to disk\n",
    "\n",
    "We will often want to write our results out to a file. It's often a good idea to put these files into a new folder to keep them separate from the raw data.\n",
    "\n",
    "First, let's make a folder called `processed` inside the `data` folder. Once we make the Path object, we can use the `mkdir` attribute to make the new folder. The `parents=True` flag will create any missing parent folders, and `exist_ok=True` prevents an error if the folder already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = Path(\"data\") / \"processed\"\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c607e",
   "metadata": {},
   "source": [
    "Let's write a simple table of replicate counts into the `processed` folder. Each row will have the drug name and how many replicate CSV files were found.\n",
    "\n",
    "We will use `csv.writer`, which writes one row at a time. First we write the header with `writerow([\"drug\", \"n_replicates\"])`, then in a loop we call `writerow([...])` for each drug. The `open` command creates the file (in write mode) and `newline=\"\"` prevents extra blank lines on some systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate_counts_path = processed_dir / \"replicate_counts.csv\"\n",
    "\n",
    "with open(replicate_counts_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"drug\", \"n_replicates\"])\n",
    "    for i in range(len(drug_folders)):\n",
    "        writer.writerow([drug_folders[i].name, replicate_counts[i]])\n",
    "\n",
    "print(\"Wrote:\", replicate_counts_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1365a",
   "metadata": {},
   "source": [
    "## Introduction to pandas\n",
    "\n",
    "So far we have used `pathlib` for navigating folders and the `csv` module for writing data files. These tools work, but when working with tabular data (rows and columns like a spreadsheet), there is a more powerful and convenient tool: **pandas**.\n",
    "\n",
    "Pandas is the standard Python library for working with tabular data. It provides:\n",
    "\n",
    "- **DataFrames**: A structure similar to a spreadsheet with named columns\n",
    "- **Easy CSV reading and writing**: Handles headers, mixed data types, and missing values automatically\n",
    "- **Intuitive column access**: Use names instead of numerical indices\n",
    "- **Powerful filtering and grouping**: Select rows based on conditions, aggregate data by categories\n",
    "- **Integration with plotting**: DataFrames can plot themselves\n",
    "\n",
    "We won't cover pandas in depth in this lecture, but let's see how it can simplify some of the tasks we just did. Think of this as a preview of a tool you will use often in data analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7239f6",
   "metadata": {},
   "source": [
    "### Importing pandas\n",
    "\n",
    "Like NumPy and matplotlib, pandas is not part of core Python and must be imported. The standard convention is to import it as `pd`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb57cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d0182",
   "metadata": {},
   "source": [
    "### Reading CSV files with pandas\n",
    "\n",
    "Earlier in this course we used `np.loadtxt` to read CSV files. This works, but has limitations:\n",
    "\n",
    "- You must manually skip header rows with `skiprows=1`\n",
    "- All data must be numeric (strings cause errors)\n",
    "- You access columns by numerical index (was Time column 0 or 1?)\n",
    "\n",
    "Pandas makes this much easier. Let's load one of the growth curve CSV files we saw earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9512ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a growth curve file using pandas into a dataframe called `df`\n",
    "df = pd.read_csv(example_csv_files[0])\n",
    "\n",
    "print(\"File loaded:\", example_csv_files[0])\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c452cb",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "\n",
    "- Pandas automatically recognized and used the header row\n",
    "- The output displays as a nice table\n",
    "- `.head()` shows the first 5 rows by default\n",
    "\n",
    "The object `df` is a **DataFrame**, which is like a table where each column has a name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683593be",
   "metadata": {},
   "source": [
    "### Accessing columns by name\n",
    "\n",
    "With NumPy arrays, we had to remember that Time was column 0 and OD was column 1. With pandas, we can use the column names directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08461c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access columns by name\n",
    "time = df['Time']\n",
    "od = df['OD']\n",
    "\n",
    "print(\"First time:\", time.iloc[0])\n",
    "print(\"Last time:\", time.iloc[-1])\n",
    "print(\"First OD:\", od.iloc[0])\n",
    "print(\"Last OD:\", od.iloc[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0263e",
   "metadata": {},
   "source": [
    "Much more readable! `df['Time']` says \"get the Time column\" in plain English.\n",
    "\n",
    "If you need a NumPy array from a pandas column (for example, to use with matplotlib), you can convert it with `.values`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array = df['Time'].values\n",
    "od_array = df['OD'].values\n",
    "\n",
    "print(\"Type of df['Time']:\", type(df['Time']))\n",
    "print(\"Type of df['Time'].values:\", type(time_array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b287a51",
   "metadata": {},
   "source": [
    "### Writing CSV files with pandas\n",
    "\n",
    "Earlier we used the `csv` module to write our replicate counts table. It took several lines and required a loop. With pandas, we can do the same thing much more simply.\n",
    "\n",
    "First, let's build a DataFrame from our drug names and replicate counts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from our drug data\n",
    "results_df = pd.DataFrame({\n",
    "    'drug': [f.name for f in drug_folders],\n",
    "    'n_replicates': replicate_counts\n",
    "})\n",
    "\n",
    "print(\"DataFrame contents:\")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a1e6c3",
   "metadata": {},
   "source": [
    "Now we can write it to a CSV file with a single line:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071dfa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV using pandas\n",
    "pandas_output_path = processed_dir / \"replicate_counts_pandas.csv\"\n",
    "results_df.to_csv(pandas_output_path, index=False)\n",
    "\n",
    "print(\"Wrote:\", pandas_output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5605255",
   "metadata": {},
   "source": [
    "Compare this to the `csv` module version we wrote earlier:\n",
    "\n",
    "```python\n",
    "# The csv module way (7 lines)\n",
    "with open(replicate_counts_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"drug\", \"n_replicates\"])\n",
    "    for i in range(len(drug_folders)):\n",
    "        writer.writerow([drug_folders[i].name, replicate_counts[i]])\n",
    "\n",
    "# The pandas way (1 line, after creating the DataFrame)\n",
    "results_df.to_csv(pandas_output_path, index=False)\n",
    "```\n",
    "\n",
    "The `index=False` parameter tells pandas not to write row numbers to the file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b80ffe",
   "metadata": {},
   "source": [
    "### Combining pathlib and pandas\n",
    "\n",
    "One powerful pattern is to use **pathlib for navigation** and **pandas for data**.\n",
    "\n",
    "Here's an example that loads all CSV files from a drug folder and computes the average final OD:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcdc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pathlib to find files\n",
    "drug_folder = drug_folders[0]\n",
    "csv_files = list(drug_folder.glob(\"*.csv\"))\n",
    "\n",
    "# Use pandas to load and process data\n",
    "final_ods = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    final_od = df['OD'].iloc[-1]  # Last OD value\n",
    "    final_ods.append(final_od)\n",
    "\n",
    "average_final_od = np.mean(final_ods)\n",
    "\n",
    "print(f\"Drug: {drug_folder.name}\")\n",
    "print(f\"Number of replicates: {len(csv_files)}\")\n",
    "print(f\"Final OD values: {final_ods}\")\n",
    "print(f\"Average final OD: {average_final_od:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
