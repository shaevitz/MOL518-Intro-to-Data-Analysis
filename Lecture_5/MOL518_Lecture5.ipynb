{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In colab run this cell first to setup the file structure!\n",
    "%cd /content\n",
    "!rm -rf MOL518-Intro-to-Data-Analysis\n",
    "\n",
    "!git clone https://github.com/shaevitz/MOL518-Intro-to-Data-Analysis.git\n",
    "%cd MOL518-Intro-to-Data-Analysis/Lecture_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf2bdd",
   "metadata": {},
   "source": [
    "# Lecture 5: Working with files and folders\n",
    "\n",
    "In scientific computing, you will often need to work with many files organized into folders (also called directories). If you have experience using the command line (Terminal on Mac or Command Prompt/PowerShell on Windows), this will feel familiar. If you have only ever navigated files by clicking through Finder (Mac) or File Explorer (Windows), this programmatic approach may feel new, but it is a powerful skill that will save you time when processing large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11465957",
   "metadata": {},
   "source": [
    "The goals of this lecture are to:\n",
    "\n",
    "- Learn about the working directory\n",
    "- Build paths using `pathlib.Path`\n",
    "- List the contents of a folder from inside Python\n",
    "- Find groups of files using patterns\n",
    "- Loop over many files and compute summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11094b9b",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We will need to import two new packages\n",
    "\n",
    "- `pathlib.Path` for working with file paths\n",
    "- `csv` module for writing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09565f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393a03e",
   "metadata": {},
   "source": [
    "## Navigating the file system\n",
    "\n",
    "### Files and folders\n",
    "- A **folder** (also called a directory) can contain files and other folders.\n",
    "- A **file** holds content, such as numbers in a CSV file, text in a document, or pixels in an image.\n",
    "\n",
    "### File extensions\n",
    "A file extension is the suffix after the last dot in a filename and is used to give you information about what is stored in the file.\n",
    "\n",
    "- `growth_curve.csv` has the extension `.csv`. A `Comma-Separated Values` file is a plain text file format for storing tabular data, where each row is a data record and columns are separated by commas (or other characters like tabs or semi-colons).\n",
    "- A `.jpg` file contains an image ...\n",
    "\n",
    "\n",
    "### Paths\n",
    "A **path** is a description of where a file or folder resides within the computer system.\n",
    "\n",
    "- A **relative path** is interpreted relative to your current working directory.\n",
    "  - Example: `data/raw/experiment.csv` (same on Mac and Windows when using Python's pathlib)\n",
    "  - Example: `../Lecture_4/data.csv` (go up one folder first)\n",
    "\n",
    "- An **absolute path** describes a location starting from the top of the file system.\n",
    "  - Mac example: `/Users/username/Documents/project/data.csv`\n",
    "  - Windows example: `C:\\Users\\username\\Documents\\project\\data.csv`\n",
    "\n",
    "> It is often useful to use relative paths because they work across different computers/systems as long as the project folder structure is consistent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283d814",
   "metadata": {},
   "source": [
    "## The working directory\n",
    "\n",
    "When Python opens a file using a relative path, what is it relative to? That reference point is called the **working directory**. You can think of it as the folder where Python is currently working.\n",
    "\n",
    "If the working directory is not what you expect, your code will fail to find files even if they exist. In Colab, the working directory can reset if you restart the runtime or open the notebook in a different way.\n",
    "\n",
    "> A good habit is to print the current working directory before you load data,  to make sure you are where you think you are.\n",
    "\n",
    "`Path` is a class that represents file and folder paths. Classes are collections of related functionality bundled together. We've seen this before: in Lecture 2 we used `np.array()` to create NumPy arrays, and in Lecture 3 we used methods like `.plot()` on matplotlib objects.\n",
    "\n",
    "`Path.cwd()` is a function that belongs to the `Path` class that returns the current working directory as a Path object. The parentheses `()` mean we are *calling* the method to execute it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "252982be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/jshaevitz/Library/CloudStorage/Dropbox/Documents/Teaching/MOL518_Programming/MOL518-Intro-to-Data-Analysis/Lecture_5')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current working directory as a Path object.\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165492b",
   "metadata": {},
   "source": [
    "If you ran the setup cell at the top of this notebook, your working directory should look like:\n",
    "\n",
    "`/content/MOL518-Intro-to-Data-Analysis/Lecture_5`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c2f8ec",
   "metadata": {},
   "source": [
    "## Listing the contents of a folder\n",
    "\n",
    "We can still explore the the contents of a folder from inside Python.\n",
    "\n",
    "The `Path.iterdir()` function lists the contents of a folder. It returns a sequence of **Path objects**. We will use the `list()` function to convert it to a list so we can print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc4c1a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/jshaevitz/Library/CloudStorage/Dropbox/Documents/Teaching/MOL518_Programming/MOL518-Intro-to-Data-Analysis/Lecture_5/MOL518_Lecture5.ipynb'),\n",
       " PosixPath('/Users/jshaevitz/Library/CloudStorage/Dropbox/Documents/Teaching/MOL518_Programming/MOL518-Intro-to-Data-Analysis/Lecture_5/data')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the contents of the current working directory\n",
    "entries = list(Path.cwd().iterdir())\n",
    "entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee1209",
   "metadata": {},
   "source": [
    "## Building paths with `pathlib.Path`\n",
    "\n",
    "In earlier lectures we have written the filename directly into the code cells. That works, but it becomes tedious if you have many files and fragile when you start combining folders and filenames.\n",
    "\n",
    "`pathlib.Path` lets you build paths in a way that works across systems and operating systems.\n",
    "\n",
    "You can join path pieces using `/`. For example, `Path(\"data\") / \"ecoli_drug_curves\"` means: a folder named `ecoli_drug_curves` inside a folder named `data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c24f736b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/ecoli_drug_curves')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"data\") / \"ecoli_drug_curves\"\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50200ee4",
   "metadata": {},
   "source": [
    "Before we do anything with a path, it's good to check whether it exists:\n",
    "\n",
    "- `.exists()` tells you whether something is there\n",
    "- `.is_dir()` tells you whether it is a folder\n",
    "- `.is_file()` tells you whether it is a file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9471ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir.exists(), data_dir.is_dir(), data_dir.is_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b1b9c",
   "metadata": {},
   "source": [
    "## Navigating a complex directory structure\n",
    "\n",
    "For this lecture, I have put the antibiotic growth curve replicates into folders based on the drug name via the following convention:\n",
    "\n",
    "- `data/ecoli_drug_curves/DrugName/DrugName_rep1.csv`\n",
    "- `data/ecoli_drug_curves/DrugName/DrugName_rep2.csv`\n",
    "\n",
    "We'll start by listing all the folders inside `data/` that represent the different drugs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e3e79af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/ecoli_drug_curves/Ampicillin'),\n",
       " PosixPath('data/ecoli_drug_curves/Trimethoprim'),\n",
       " PosixPath('data/ecoli_drug_curves/Novabiocin'),\n",
       " PosixPath('data/ecoli_drug_curves/Gentamycin'),\n",
       " PosixPath('data/ecoli_drug_curves/Rifampicin'),\n",
       " PosixPath('data/ecoli_drug_curves/Chloramphenicol')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_dir.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdb5dc7",
   "metadata": {},
   "source": [
    "Let's make a nicer list alphabetized by drug name. \n",
    "\n",
    "First, we will use a `for` loop to go through the contents of `data_dir` and keep only the items that are folders (not files). Then we will sort the list alphabetically.\n",
    "\n",
    "Note that the `.name` attribute of a Path object returns only the final component of the path, i.e. just the filename or the last folder name, without any of the parent directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80b2b973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug folders found:\n",
      "Ampicillin\n",
      "Chloramphenicol\n",
      "Gentamycin\n",
      "Novabiocin\n",
      "Rifampicin\n",
      "Trimethoprim\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Build a list of only the folders (not files) in data_dir\n",
    "drug_folders_list = []\n",
    "for p in data_dir.iterdir():\n",
    "    if p.is_dir():\n",
    "        drug_folders_list.append(p) # appends the current folder to the list\n",
    "\n",
    "# Step 2: Sort them alphabetically by name\n",
    "drug_folders = sorted(drug_folders_list)\n",
    "\n",
    "# Step 3: Print a clean list of folder names\n",
    "print(\"Drug folders found:\")\n",
    "for p in drug_folders:\n",
    "    print(p.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c83cd",
   "metadata": {},
   "source": [
    "Above we used the `sorted` function which takes a list or sequence and returns a new list with the same items arranged in order (alphabetically for text, numerically for numbers). This makes the output easier to read.\n",
    "\n",
    "## Finding files with patterns using `glob`\n",
    "\n",
    "Sometimes you want to load all files of a particular type from a folder, like \"all CSV files in this directory\" or \"all PNG images from this experiment\".\n",
    "\n",
    "The `glob` method finds file paths that match a pattern using **wildcards**:\n",
    "\n",
    "- `*.csv` means: any filename that ends in `.csv`\n",
    "- `data_*.txt` means: any filename that starts with `data_` and ends in `.txt`\n",
    "- `*` by itself means: everything\n",
    "\n",
    "Wildcards are a quick way to describe groups of files without listing each one by hand. Note, the `glob` function only finds the paths; it does not load or open the files.\n",
    "\n",
    "Let's list all the CSV files inside one the first drug folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfbdb1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/ecoli_drug_curves/Ampicillin')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick the first drug folder in the list\n",
    "example_drug_dir = drug_folders[0]\n",
    "example_drug_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a03f0",
   "metadata": {},
   "source": [
    "If we list all the files, we see there are some non-CSV files with other information in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "070e73f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/ecoli_drug_curves/Ampicillin/OtherInfo.txt'),\n",
       " PosixPath('data/ecoli_drug_curves/Ampicillin/Ampicillin_rep2.csv'),\n",
       " PosixPath('data/ecoli_drug_curves/Ampicillin/Ampicillin_rep1.csv')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(example_drug_dir.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48546380",
   "metadata": {},
   "source": [
    "We can use `*.csv` to find only the CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13dd2bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CSV files found: 2\n",
      "Ampicillin_rep1.csv\n",
      "Ampicillin_rep2.csv\n"
     ]
    }
   ],
   "source": [
    "example_csv_files = sorted(list(example_drug_dir.glob(\"*.csv\")))\n",
    "\n",
    "print(\"Number of CSV files found:\", len(example_csv_files))\n",
    "for p in example_csv_files:\n",
    "    print(p.name) # Note, here name prints the filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387b159",
   "metadata": {},
   "source": [
    "## Loading one growth curve file\n",
    "\n",
    "Each growth curve CSV contains two columns as before, Time and OD. The first row is a header, so we need to remember to tell NumPy to skip it.\n",
    "\n",
    "Here is example code that loads the first file in `example_drug_dir` and prints some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b918bd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Ampicillin_rep1.csv\n",
      "Number of time points: 97\n",
      "First time: 0.0\n",
      "Last time: 960.0\n",
      "First OD: 0.116\n",
      "Last OD: 0.114\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(example_csv_files[0], delimiter=\",\", skiprows=1)\n",
    "\n",
    "time = data[:, 0]\n",
    "od = data[:, 1]\n",
    "\n",
    "print(\"File:\", example_csv_files[0].name)\n",
    "print(\"Number of time points:\", len(time))\n",
    "print(\"First time:\", time[0])\n",
    "print(\"Last time:\", time[-1])\n",
    "print(\"First OD:\", od[0])\n",
    "print(\"Last OD:\", od[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f443f24",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write code to load both CSV files in `example_drug_dir` and calculate the average Last OD measurement. Use paths and a for loop over the files as we've been discussing for your code rather than hard coding the file names etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c161df3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Ampicillin_rep1.csv, Last OD: 0.114\n",
      "File: Ampicillin_rep2.csv, Last OD: 0.115\n",
      "\n",
      "Average last OD: 0.1145\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f96842",
   "metadata": {},
   "source": [
    "## Extracting metadata from filenames\n",
    "\n",
    "In real workflows, important information often lives in folder names and filenames.\n",
    "\n",
    "Our files follow a simple naming pattern:\n",
    "\n",
    "`DrugName_rep1.csv`\n",
    "\n",
    "The part before `.csv` is called the **stem**.\n",
    "\n",
    "We can access pieces of a path like this:\n",
    "\n",
    "- `path.name` gives the full filename\n",
    "- `path.stem` gives the filename without the extension\n",
    "\n",
    "Below we print the Path, name, and stem of `example_csv_files[0]`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b1a8cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/ecoli_drug_curves/Ampicillin/Ampicillin_rep1.csv'),\n",
       " 'Ampicillin_rep1.csv',\n",
       " 'Ampicillin_rep1')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_csv_files[0], example_csv_files[0].name, example_csv_files[0].stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941cc7ec",
   "metadata": {},
   "source": [
    "## Batch processing all replicates for one drug\n",
    "\n",
    "Now we scale up from one file to many.\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Find all replicate CSV files for a drug folder\n",
    "2. Summarize each file\n",
    "3. Create a small table that has one row per replicate\n",
    "4. Compute the average last OD across replicates\n",
    "\n",
    "In the full batch processing section, we will save one replicate table per drug to disk.\n",
    "That table will include:\n",
    "\n",
    "- Replicate number\n",
    "- Total number of time points\n",
    "- Average last OD for that drug (the same number repeated for each replicate row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e434e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dir = example_drug_dir\n",
    "replicate_files = sorted(list(drug_dir.glob(\"*.csv\")))\n",
    "\n",
    "replicate_rows = []\n",
    "\n",
    "for csv_path in replicate_files:\n",
    "    row = summarize_growth_curve(csv_path)\n",
    "    replicate_rows.append(row)\n",
    "\n",
    "print(\"Drug:\", drug_dir.name)\n",
    "print(\"Number of replicate files:\", len(replicate_rows))\n",
    "\n",
    "# Print the table in a readable way\n",
    "for row in replicate_rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dfa9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average last OD across replicates\n",
    "last_ods = [row[\"last_od\"] for row in replicate_rows]\n",
    "\n",
    "avg_last_od = sum(last_ods) / len(last_ods)\n",
    "print(\"Average last OD for\", drug_dir.name, \":\", avg_last_od)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e109523",
   "metadata": {},
   "source": [
    "This average is a simple summary of growth under that drug condition.\n",
    "\n",
    "In later lectures you will learn more sophisticated summaries, but the workflow pattern will stay the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e195a",
   "metadata": {},
   "source": [
    "## Writing output tables to disk\n",
    "\n",
    "In a real workflow, you do not want results only printed to the screen.\n",
    "\n",
    "You want to save them so you can:\n",
    "\n",
    "- Load them later\n",
    "- Share them\n",
    "- Plot them\n",
    "\n",
    "We will save outputs in a separate folder.\n",
    "\n",
    "We will never overwrite the raw data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = Path(\"data\") / \"processed\"\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the per replicate table for this drug\n",
    "output_path = processed_dir / f\"{drug_dir.name}_replicate_table.csv\"\n",
    "\n",
    "fieldnames = [\"replicate\", \"last_od\", \"n_time_points\", \"elapsed_time\", \"file\"]\n",
    "\n",
    "with open(output_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(replicate_rows)\n",
    "\n",
    "print(\"Wrote:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ca7f2",
   "metadata": {},
   "source": [
    "## Full batch processing: all drugs\n",
    "\n",
    "Now we do the same procedure for every drug folder.\n",
    "\n",
    "For each drug we will:\n",
    "\n",
    "- Find the replicate files\n",
    "- Compute a small summary for each replicate\n",
    "- Compute the average last OD across the replicates\n",
    "- Save a table for that drug in `data/processed`\n",
    "\n",
    "Each per drug table will have one row per replicate with these columns:\n",
    "\n",
    "- `replicate`\n",
    "- `n_time_points`\n",
    "- `avg_last_od` (the average across replicates for that drug)\n",
    "\n",
    "We will also build an overall summary table that has one row per drug.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5600e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "\n",
    "drug_summary_rows = []\n",
    "failed_files = []\n",
    "\n",
    "for drug_dir in drug_folders:\n",
    "    replicate_files = sorted(list(drug_dir.glob(\"*.csv\")))\n",
    "\n",
    "    replicate_rows = []\n",
    "\n",
    "    for csv_path in replicate_files:\n",
    "        try:\n",
    "            row = summarize_growth_curve(csv_path)\n",
    "            replicate_rows.append(row)\n",
    "        except Exception as e:\n",
    "            failed_files.append({\"drug\": drug_dir.name, \"file\": csv_path.name, \"error\": str(e)})\n",
    "            if verbose:\n",
    "                print(\"Failed:\", drug_dir.name, csv_path.name)\n",
    "                print(\"Error:\", e)\n",
    "\n",
    "    if len(replicate_rows) == 0:\n",
    "        if verbose:\n",
    "            print(\"No replicate files found for\", drug_dir.name)\n",
    "        continue\n",
    "\n",
    "    # Compute average last OD across replicates for this drug\n",
    "    last_ods = [row[\"last_od\"] for row in replicate_rows]\n",
    "    avg_last_od = sum(last_ods) / len(last_ods)\n",
    "\n",
    "    # Build a per drug table where each row is one replicate.\n",
    "    # Each row includes the drug average, repeated, because it is a per drug value.\n",
    "    per_drug_table_rows = []\n",
    "    for row in replicate_rows:\n",
    "        per_drug_table_rows.append({\n",
    "            \"replicate\": row[\"replicate\"],\n",
    "            \"n_time_points\": row[\"n_time_points\"],\n",
    "            \"avg_last_od\": avg_last_od,\n",
    "        })\n",
    "\n",
    "    # Save the per drug replicate table\n",
    "    per_drug_output = processed_dir / f\"{drug_dir.name}_replicate_table.csv\"\n",
    "    fieldnames = [\"replicate\", \"n_time_points\", \"avg_last_od\"]\n",
    "\n",
    "    with open(per_drug_output, \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(per_drug_table_rows)\n",
    "\n",
    "    # Add one row to the overall drug summary table\n",
    "    drug_summary_rows.append({\n",
    "        \"drug\": drug_dir.name,\n",
    "        \"n_replicates\": len(replicate_rows),\n",
    "        \"avg_last_od\": avg_last_od,\n",
    "    })\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Processed\", drug_dir.name, \"with\", len(replicate_rows), \"replicates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the overall drug summary table\n",
    "summary_output = processed_dir / \"drug_summary_table.csv\"\n",
    "\n",
    "with open(summary_output, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"drug\", \"n_replicates\", \"avg_last_od\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(drug_summary_rows)\n",
    "\n",
    "print(\"Wrote:\", summary_output)\n",
    "print(\"Number of drugs summarized:\", len(drug_summary_rows))\n",
    "\n",
    "if len(failed_files) > 0:\n",
    "    print(\"\n",
    "Some files failed to process. Here are the failures:\")\n",
    "    for item in failed_files:\n",
    "        print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21caf70a",
   "metadata": {},
   "source": [
    "If you want to double check your results, open one of the saved CSV files in `data/processed`.\n",
    "\n",
    "The most important outcome of this lecture is not the specific numbers, but the workflow:\n",
    "\n",
    "- Find files\n",
    "- Loop\n",
    "- Summarize\n",
    "- Save outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d164dab",
   "metadata": {},
   "source": [
    "## Reporting failures\n",
    "\n",
    "In batch processing, one bad file should not crash everything.\n",
    "\n",
    "At the same time, you should never silently ignore failures.\n",
    "\n",
    "We kept a list of failed files, if any. Let us print it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(failed_files) == 0:\n",
    "    print(\"No failures detected.\")\n",
    "else:\n",
    "    print(\"Failures:\")\n",
    "    for item in failed_files:\n",
    "        print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d13692c",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 2\n",
    "Modify `summarize_growth_curve` so it also returns the first OD value.\n",
    "\n",
    "### Exercise 3\n",
    "For each drug, check whether the two replicates have the same number of time points. If not, print a warning.\n",
    "\n",
    "### Exercise 4\n",
    "Create a new summary table that includes the elapsed time for each drug. One simple choice is to average the elapsed times across replicates.\n",
    "\n",
    "Work slowly and use the habits from this lecture.\n",
    "\n",
    "- Print the paths you are using\n",
    "- Print the number of files found\n",
    "- Print a few intermediate results before writing files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa71bc",
   "metadata": {},
   "source": [
    "## Common failure modes\n",
    "\n",
    "- Forgetting that relative paths depend on the working directory\n",
    "- Typing folder names that do not match the actual names on disk\n",
    "- Using `glob` and not checking whether you found the files you expected\n",
    "- Confusing a `Path` object with the file contents\n",
    "- Writing outputs into the wrong folder and then not being able to find them\n",
    "\n",
    "If you get stuck, the most important debugging step is still the simplest.\n",
    "\n",
    "Print what you think you are using, then compare it to what is actually happening.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
